{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DBRF import DBRF\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgbm\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "import csv\n",
    "from datetime import date\n",
    "from sklearn.utils.fixes import loguniform\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "import time\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = [f for f in listdir('classification_datasets') if isfile(join('classification_datasets', f))]\n",
    "all_files = sorted(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == object:\n",
    "            df = pd.get_dummies(df, columns=[col])\n",
    "            \n",
    "    if df[df.columns[-1]].dtype == object:\n",
    "        last_col = df.columns[-1]\n",
    "        df['new_class'] = pd.factorize(df[last_col])[0]\n",
    "        df = df[[i for i in df.columns if i != last_col]]\n",
    "            \n",
    "    df = df.interpolate()\n",
    "    df.fillna(value=0.0, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_params(D, file_name):\n",
    "    \n",
    "    Data_params = []\n",
    "    \n",
    "    X = D[D.columns[:-1]]\n",
    "    y = D[D.columns[-1]]\n",
    "\n",
    "    #10-fold cross validation\n",
    "    kf = KFold(n_splits=10, shuffle=True)\n",
    "    CV_num = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "#         print('CV_num -',CV_num)\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        best_n, best_ests, best_crit = find_params(X_train, y_train)\n",
    "            \n",
    "        classifier = DBRF(best_n, best_ests, best_crit)\n",
    "\n",
    "        #time.process_time() will measure the CPU time\n",
    "        start1 = time.process_time()\n",
    "        classifier.fit(X_train, y_train)\n",
    "        train_time = time.process_time() - start1\n",
    "\n",
    "        #prediction\n",
    "        start2 = time.process_time()\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        predict_time = time.process_time() - start2\n",
    "\n",
    "        #dataframe size\n",
    "        r, c = X_test.shape\n",
    "\n",
    "        # Scale\n",
    "        infer_time = predict_time*(1000/r)\n",
    "\n",
    "        #Accuracy\n",
    "        #preds_classes = [x.index(max(x)) for x in prediction_probab]\n",
    "        acc_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # TPR, FPR ,Precision\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred, labels=[0,1]).ravel()\n",
    "\n",
    "        # Sensitivity, hit rate, recall, or true positive rate\n",
    "        TPR = tp/(tp+fn)\n",
    "\n",
    "        # Fall out or false positive rate\n",
    "        FPR = fp/(fp+tn)\n",
    "\n",
    "\n",
    "        # Precision or positive predictive value\n",
    "        #Precision = tp/(tp+fp)\n",
    "        precision = precision_score(y_test, y_pred, average='binary')\n",
    "\n",
    "        score = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "        #Area under Precision-Recall Curve \n",
    "        average_precision = average_precision_score(y_test, y_prob)\n",
    "\n",
    "        hyper = 'n = '+str(round(best_n))+'. ests = '+str(round(best_ests))+'. criterion = '+str(best_crit)+\".\"\n",
    "\n",
    "        params = {'Dataset Name': file_name, \n",
    "                  'Algorithm Name': 'DBRF',\n",
    "                  'Cross Validation': CV_num, \n",
    "                  'Hyper-Parameters Values': hyper,\n",
    "                  'Accuracy':acc_score,\n",
    "                  'TPR':TPR,\n",
    "                  'FPR':FPR,\n",
    "                  'Precision':precision,\n",
    "                  'AUC':score,\n",
    "                  'PR-Curve':average_precision,\n",
    "                  'Training Time':train_time,\n",
    "                  'Inference Time':infer_time}\n",
    "\n",
    "        Data_params.append(params)\n",
    "        CV_num += 1\n",
    "\n",
    "    return Data_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_params(X_train, y_train):\n",
    "    clf = DBRF(5)\n",
    "    param_dist = {'criterion': ['gini', 'entropy'],\n",
    "                  'n_estimators': stats.uniform(5, 30),\n",
    "                  'n' : stats.uniform(1, 10)}\n",
    "    random_search = RandomizedSearchCV(clf, param_distributions=param_dist,n_iter=50,cv=3, random_state=0, n_jobs=2)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    x = random_search.best_params_ \n",
    "    return x['n'], x['n_estimators'], x['criterion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_params(D, file_name, num_uni):\n",
    "    \n",
    "    Data_params = []\n",
    "\n",
    "    X = D[D.columns[:-1]]\n",
    "    y = D[D.columns[-1]]\n",
    "    \n",
    "    #10-fold cross validation\n",
    "    kf = KFold(n_splits=10, shuffle=True)\n",
    "    CV_num = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "\n",
    "        best_n, best_ests, best_crit = find_params(X_train, y_train)\n",
    "\n",
    "        dbrf = DBRF(best_n, best_ests, best_crit)\n",
    "\n",
    "        classifier  = OneVsRestClassifier(dbrf)\n",
    "\n",
    "        #time.process_time() will measure the CPU time\n",
    "        start1 = time.process_time()\n",
    "        clf = classifier.fit(X_train, y_train)\n",
    "        train_time = time.process_time() - start1\n",
    "\n",
    "        #prediction\n",
    "        start2 = time.process_time()\n",
    "        y_pred = clf.predict(X_test)\n",
    "        predict_time = time.process_time() - start2\n",
    "\n",
    "\n",
    "        #dataframe size\n",
    "        r, c = X_test.shape\n",
    "\n",
    "        # Scale\n",
    "        infer_time = predict_time*(1000/r)\n",
    "\n",
    "        #Accuracy\n",
    "        #In binary and multiclass classification, this function is equal to the jaccard_score function (doc.)\n",
    "        acc_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        #auc calculate\n",
    "        y_prob = clf.predict_proba(X_test)\n",
    "\n",
    "        \n",
    "        new_test = np.zeros((y_test.size, num_uni+1))\n",
    "        new_test[np.arange(y_test.size),y_test] = 1\n",
    "\n",
    "        macro_roc_auc_ovr = roc_auc_score(new_test, y_prob, multi_class=\"ovr\", average=\"macro\")\n",
    "        #Area under Precision-Recall Curve\n",
    "\n",
    "        #AP and the trapezoidal area under the operating points (sklearn.metrics.auc)\n",
    "        #are common ways to summarize a precision-recall curve that lead to different results.\n",
    "\n",
    "        # for use average_precision_score it is necessary to binarize the output of predict_proba\n",
    "        # predict_proba returns the probability of the sample for each class in the model,\n",
    "        #where classes are ordered as they are in self.classes\n",
    "\n",
    "\n",
    "        # binarize\n",
    "        label_y_test = label_binarize(y_test, classes= clf.classes_)\n",
    "\n",
    "        average_precision =  average_precision_score(label_y_test, y_prob, average='macro')\n",
    "\n",
    "\n",
    "        # TPR, FPR\n",
    "        # confusion matrix\n",
    "        cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        # computetion of TPR and FPR for each class\n",
    "        FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix) \n",
    "        FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
    "        TP = np.diag(cnf_matrix)\n",
    "        TN = cnf_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "        FP = FP.astype(float)\n",
    "        FN = FN.astype(float)\n",
    "        TP = TP.astype(float)\n",
    "        TN = TN.astype(float)\n",
    "\n",
    "        # Sensitivity, hit rate, recall, or true positive rate\n",
    "        TPR = TP/(TP+FN)\n",
    "        # Fall out or false positive rate\n",
    "        FPR = FP/(FP+TN)\n",
    "        # Precision or positive predictive value\n",
    "        PPV = TP/(TP+FP)\n",
    "\n",
    "        # macro average\n",
    "        classes_num = clf.n_classes_\n",
    "        macro_TPR= sum(TPR)/classes_num\n",
    "        macro_FPR= sum(FPR)/classes_num\n",
    "        macro_PPV= sum(PPV)/classes_num\n",
    "\n",
    "        # Precision\n",
    "        precision = precision_score(y_test, y_pred, average='macro')\n",
    "\n",
    "        #save all calculations in a dictionary\n",
    "        hyper = 'n = '+str(best_n)+'. ests = '+str(best_ests)+'. criterion = '+str(best_crit)+\".\"\n",
    "\n",
    "\n",
    "        params = {'Dataset Name': file_name, \n",
    "                  'Algorithm Name': 'DBRF',\n",
    "                  'Cross Validation': CV_num, \n",
    "                  'Hyper-Parameters Values': hyper,\n",
    "                  'Accuracy':acc_score,\n",
    "                  'TPR':macro_TPR,\n",
    "                  'FPR':macro_FPR,\n",
    "                  'Precision':precision,\n",
    "                  'AUC':macro_roc_auc_ovr,\n",
    "                  'PR-Curve':average_precision,\n",
    "                  'Training Time':train_time,\n",
    "                  'Inference Time':infer_time}\n",
    "    #             print(params)\n",
    "\n",
    "        Data_params.append(params)\n",
    "        CV_num += 1\n",
    "\n",
    "    return Data_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da84fabc9e344c15a99063e6d98b3a8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=150.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <DBRF.DBRF object at 0x000002A11E59F9B0>, as the constructor either does not set or modifies parameter n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-fdfd214c586c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmulti_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-f6db7b287f94>\u001b[0m in \u001b[0;36mmulti_params\u001b[1;34m(D, file_name, num_uni)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mbest_n\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_ests\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_crit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mdbrf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDBRF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_n\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_ests\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_crit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-41807e683fe8>\u001b[0m in \u001b[0;36mfind_params\u001b[1;34m(X_train, y_train)\u001b[0m\n\u001b[0;32m      5\u001b[0m                   'n' : stats.uniform(1, 10)}\n\u001b[0;32m      6\u001b[0m     \u001b[0mrandom_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_distributions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_dist\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mrandom_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'n'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'n_estimators'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'criterion'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;31m# of the params are estimators as well.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[1;32m--> 762\u001b[1;33m                 **self.best_params_))\n\u001b[0m\u001b[0;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     96\u001b[0m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[0;32m     97\u001b[0m                                \u001b[1;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m                                (estimator, name))\n\u001b[0m\u001b[0;32m     99\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Cannot clone object <DBRF.DBRF object at 0x000002A11E59F9B0>, as the constructor either does not set or modifies parameter n"
     ]
    }
   ],
   "source": [
    "all_results = dict()\n",
    "for file in tqdm(all_files):\n",
    "    \n",
    "    D = load_data('classification_datasets/'+file)     \n",
    "\n",
    "    if D.nunique()[D.columns[-1]] > 2:\n",
    "        params = multi_params(D, file, D.nunique()[D.columns[-1]])\n",
    "\n",
    "    if D.nunique()[D.columns[-1]] == 2:\n",
    "        params = binary_params(D, file)\n",
    "\n",
    "    all_results[file] = params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
